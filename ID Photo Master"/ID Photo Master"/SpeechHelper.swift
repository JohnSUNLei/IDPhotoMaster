//
//  SpeechHelper.swift
//  ID Photo Master
//
//  Created by ç¥é¾™å¤§ä¾  (Dragon Warrior) on 2026-01-06.
//

import SwiftUI
import Combine
import AVFoundation // ğŸ‘ˆ è¯­éŸ³åŠŸèƒ½å¿…é¡»å¼•å…¥è¿™ä¸ª

/// è¯­éŸ³åŠ©æ‰‹ï¼šæä¾›è¯­éŸ³æç¤ºå’ŒæŒ‡å¯¼
// å…³é”®ä¿®æ”¹ï¼šå¿…é¡»ç»§æ‰¿ NSObjectï¼Œæ‰èƒ½å¤„ç†è¯­éŸ³æ’­æ”¾å®Œæˆçš„å›è°ƒ
class SpeechHelper: NSObject, ObservableObject, AVSpeechSynthesizerDelegate {
    // MARK: - å‘å¸ƒå±æ€§
    @Published var isSpeaking = false
    @Published var isVoiceEnabled = true
    
    // MARK: - ç§æœ‰å±æ€§
    private let synthesizer = AVSpeechSynthesizer()
    private var lastSpokenMessage = ""
    private var lastSpokenTime = Date.distantPast
    private let minInterval: TimeInterval = 3.0 // æœ€å°è¯­éŸ³é—´éš”æ—¶é—´
    
    // MARK: - åˆå§‹åŒ–
    override init() {
        super.init()
        synthesizer.delegate = self
    }
    
    // MARK: - è¯­éŸ³æç¤º
    func speak(_ text: String, force: Bool = false) {
        guard isVoiceEnabled else { return }
        
        // æ£€æŸ¥æ˜¯å¦ä¸ä¸Šæ¬¡æ¶ˆæ¯ç›¸åŒä¸”æ—¶é—´é—´éš”å¤ªçŸ­
        let now = Date()
        if !force && text == lastSpokenMessage && now.timeIntervalSince(lastSpokenTime) < minInterval {
            return
        }
        
        // åœæ­¢å½“å‰è¯­éŸ³
        if synthesizer.isSpeaking {
            synthesizer.stopSpeaking(at: .immediate)
        }
        
        // åˆ›å»ºè¯­éŸ³å†…å®¹
        let utterance = AVSpeechUtterance(string: text)
        utterance.voice = AVSpeechSynthesisVoice(language: "zh-CN") // ä½¿ç”¨ä¸­æ–‡è¯­éŸ³
        utterance.rate = 0.5 // è¯­é€Ÿé€‚ä¸­
        utterance.pitchMultiplier = 1.0 // éŸ³è°ƒæ­£å¸¸
        utterance.volume = 1.0 // éŸ³é‡æœ€å¤§
        
        // å¼€å§‹è¯­éŸ³
        synthesizer.speak(utterance)
        
        // æ›´æ–°è®°å½•
        lastSpokenMessage = text
        lastSpokenTime = now
        isSpeaking = true
    }
    
    // MARK: - æ ¹æ®å§¿åŠ¿çŠ¶æ€æä¾›è¯­éŸ³æŒ‡å¯¼
    func speakGuidance(for poseStatus: PoseStatus, detailedMessage: String? = nil) {
        guard isVoiceEnabled else { return }
        
        var message = ""
        
        switch poseStatus {
        case .perfect:
            message = "å§¿åŠ¿å®Œç¾ï¼Œå¯ä»¥æ‹æ‘„è¯ä»¶ç…§"
        case .good:
            message = "å§¿åŠ¿è‰¯å¥½ï¼Œå¯ä»¥å¾®è°ƒ"
        case .needsAdjustment:
            if let detailed = detailedMessage, !detailed.isEmpty {
                message = detailed
            } else {
                message = "è¯·è°ƒæ•´å§¿åŠ¿ï¼Œå°†è„¸éƒ¨å¯¹å‡†ä¸­å¿ƒæ¡†"
            }
        case .noFace:
            message = "æœªæ£€æµ‹åˆ°äººè„¸ï¼Œè¯·å°†è„¸éƒ¨å¯¹å‡†æ¡†å†…"
        }
        
        speak(message)
    }
    
    // MARK: - æ‹æ‘„ç›¸å…³è¯­éŸ³
    func speakCaptureCountdown(_ count: Int) {
        guard isVoiceEnabled else { return }
        
        if count > 0 {
            speak("\(count)")
        } else {
            speak("æ‹ç…§")
        }
    }
    
    func speakCaptureSuccess() {
        guard isVoiceEnabled else { return }
        speak("æ‹ç…§æˆåŠŸï¼Œè¯·æŸ¥çœ‹ç…§ç‰‡")
    }
    
    func speakCaptureFailed() {
        guard isVoiceEnabled else { return }
        speak("æ‹ç…§å¤±è´¥ï¼Œè¯·é‡è¯•")
    }
    
    // MARK: - åŠŸèƒ½æç¤ºè¯­éŸ³
    func speakFlashToggle(_ isOn: Bool) {
        guard isVoiceEnabled else { return }
        speak(isOn ? "é—ªå…‰ç¯å·²å¼€å¯" : "é—ªå…‰ç¯å·²å…³é—­")
    }
    
    func speakCameraSwitch(_ isFront: Bool) {
        guard isVoiceEnabled else { return }
        speak(isFront ? "å·²åˆ‡æ¢è‡³å‰ç½®æ‘„åƒå¤´" : "å·²åˆ‡æ¢è‡³åç½®æ‘„åƒå¤´")
    }
    
    // MARK: - åœæ­¢è¯­éŸ³
    func stopSpeaking() {
        if synthesizer.isSpeaking {
            synthesizer.stopSpeaking(at: .immediate)
        }
        isSpeaking = false
    }
    
    // MARK: - åˆ‡æ¢è¯­éŸ³å¼€å…³
    func toggleVoice() {
        isVoiceEnabled.toggle()
        if !isVoiceEnabled && synthesizer.isSpeaking {
            stopSpeaking()
        }
    }
}

// MARK: - AVSpeechSynthesizerDelegate å®ç°
extension SpeechHelper {
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didFinish utterance: AVSpeechUtterance) {
        DispatchQueue.main.async {
            self.isSpeaking = false
        }
    }
    
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didCancel utterance: AVSpeechUtterance) {
        DispatchQueue.main.async {
            self.isSpeaking = false
        }
    }
}

// MARK: - è¯­éŸ³æ§åˆ¶è§†å›¾
struct VoiceControlView: View {
    @ObservedObject var speechHelper: SpeechHelper
    
    var body: some View {
        HStack {
            Button(action: {
                speechHelper.toggleVoice()
            }) {
                Image(systemName: speechHelper.isVoiceEnabled ? "speaker.wave.2.fill" : "speaker.slash.fill")
                    .font(.title2)
                    .foregroundColor(speechHelper.isVoiceEnabled ? .blue : .gray)
                    .padding(10)
                    .background(Color.black.opacity(0.3))
                    .clipShape(Circle())
            }
            
            if speechHelper.isSpeaking {
                // è¯­éŸ³æ´»åŠ¨æŒ‡ç¤ºå™¨
                HStack(spacing: 4) {
                    ForEach(0..<3) { i in
                        RoundedRectangle(cornerRadius: 2)
                            .fill(Color.blue)
                            .frame(width: 4, height: 20)
                            .animation(
                                Animation.easeInOut(duration: 0.5)
                                    .repeatForever()
                                    .delay(Double(i) * 0.1),
                                value: speechHelper.isSpeaking
                            )
                    }
                }
                .padding(.leading, 8)
            }
        }
        .padding(.horizontal)
    }
}
